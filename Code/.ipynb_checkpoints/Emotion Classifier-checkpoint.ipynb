{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:53.356899Z",
     "start_time": "2019-04-24T20:51:49.837770Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:53.370419Z",
     "start_time": "2019-04-24T20:51:53.359524Z"
    }
   },
   "outputs": [],
   "source": [
    "def fer_data_preprocessing(model):\n",
    "    '''\n",
    "    Returns the test and train data for emotion classification\n",
    "    Params: model - Enter 1 for neural network\n",
    "                    Enter 2 for all other models\n",
    "    '''\n",
    "    fer_path = '../Data/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013/fer2013.csv'\n",
    "    \n",
    "    #Loading the data from file system\n",
    "    data = pd.read_csv(fer_path)\n",
    "    \n",
    "    width, height = 48, 48\n",
    "    image_size = (width, height)\n",
    "    \n",
    "    #Extracting and processing training data\n",
    "    training_pixels = data[data['Usage'] == 'Training']['pixels'].tolist()\n",
    "    X_train = []\n",
    "    for pixel_sequence in training_pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        X_train.append(face.astype('float32'))\n",
    "    X_train = np.asarray(X_train)\n",
    "    if model == 1:\n",
    "        X_train = np.expand_dims(X_train, -1)\n",
    "    elif model == 2:\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        \n",
    "    y_train = pd.get_dummies(data[data['Usage'] == 'Training']['emotion']).values\n",
    "    \n",
    "    \n",
    "    #Loading and processing Test data\n",
    "    test_pixels = data[data['Usage'] == 'PublicTest']['pixels'].tolist()\n",
    "    X_test = []\n",
    "    for pixel_sequence in test_pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        X_test.append(face.astype('float32'))\n",
    "    X_test = np.asarray(X_test)\n",
    "    \n",
    "    # 1 for neural network\n",
    "    if model == 1:\n",
    "        X_test = np.expand_dims(X_test, -1)\n",
    "    \n",
    "    # 2 for all others\n",
    "    elif model == 2:\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    y_test = pd.get_dummies(data[data['Usage'] == 'PublicTest']['emotion']).values\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Network Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:53.383323Z",
     "start_time": "2019-04-24T20:51:53.372772Z"
    }
   },
   "outputs": [],
   "source": [
    "class Keras_NN:\n",
    "    def __init__(self,X_train, Y_train):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "    def train_model(self):\n",
    "        IMG_SIZE = 48\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(7, activation = 'softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(self.X_train, self.Y_train, batch_size=len(self.X_train)//20, epochs=20, verbose=1)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = load_model('keras_on_fer')\n",
    "        return model\n",
    "    \n",
    "    def save_model(self, model, name):\n",
    "        model.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebCam Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:53.396307Z",
     "start_time": "2019-04-24T20:51:53.387671Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_emotions(model, videoFaces, frame, bboxes):\n",
    "    '''\n",
    "    Fetches the emotions by using model prediction and adds \n",
    "    them to the output frame\n",
    "    '''\n",
    "    y_translation = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "    outputFrame = frame.copy()\n",
    "    predictions = model.predict(videoFaces)\n",
    "    for i in range(len(bboxes)):\n",
    "        emotion = y_translation[np.argmax(predictions[i])]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(outputFrame, emotion, (bboxes[i][0] -1 ,bboxes[i][1] - 1), font, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "        cv2.rectangle(outputFrame, (bboxes[i][0], bboxes[i][1]), (bboxes[i][2], bboxes[i][3]), (0, 255, 0), int(round(outputFrame.shape[0]/150)), 8)\n",
    "    return outputFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:53.409642Z",
     "start_time": "2019-04-24T20:51:53.399471Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_webcam_feed(model):\n",
    "    '''\n",
    "    Initializes webcam video for live classification\n",
    "    Extracts faces from the frame\n",
    "    Outputs the frame with predicted emotions to a window \n",
    "    '''\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    hasFrame, frame = cap.read()\n",
    "    #TODO : Handle cases for face going outside the frame\n",
    "    frame_count = 0\n",
    "    tt_opencvDnn = 0\n",
    "    while(1):\n",
    "        try:\n",
    "            hasFrame, frame = cap.read()\n",
    "            if not hasFrame:\n",
    "                break\n",
    "            frame_count += 1\n",
    "            outputFrame = frame\n",
    "            \n",
    "            #Gives a list of gray-scale images in webcam feed\n",
    "            videoFaces, bboxes = face_reduction(frame)\n",
    "            videoFaces = np.array(videoFaces)\n",
    "            if videoFaces.shape[0] != 0:\n",
    "                print(videoFaces.shape)\n",
    "                videoFaces = videoFaces.reshape((videoFaces.shape[0],videoFaces.shape[1],videoFaces.shape[2],1))\n",
    "                outputFrame = display_emotions(model, videoFaces, frame, bboxes)\n",
    "            cv2.imshow(\"frame\", outputFrame)\n",
    "            k = cv2.waitKey(10)\n",
    "            \n",
    "            # quits window when escape key is pressed\n",
    "            if k == 27:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(\"Exception is \")\n",
    "            print(e)\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:55.006188Z",
     "start_time": "2019-04-24T20:51:54.997286Z"
    }
   },
   "outputs": [],
   "source": [
    "def detectFaceOpenCVDnn(net, frame):\n",
    "    result = []\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    conf_threshold = 0.7\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            if x1 > frameWidth or x1 < 0 or x2 > frameWidth or x2 < 0 or y1 < 0 or y1 > frameHeight or y2 < 0 or y2 > frameHeight:\n",
    "                continue\n",
    "            else:\n",
    "                grayOpenDnn = gray = cv2.cvtColor(frameOpencvDnn, cv2.COLOR_BGR2GRAY)\n",
    "                croppedOpenDnn = cv2.resize(gray[y1:y2,x1:x2], (48,48)) \n",
    "                result.append(croppedOpenDnn)\n",
    "    return result, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:55.737246Z",
     "start_time": "2019-04-24T20:51:55.729235Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_reduction(image):\n",
    "    # OpenCV DNN supports 2 networks.\n",
    "    # 1. FP16 version of the original caffe implementation ( 5.4 MB )\n",
    "    # 2. 8 bit Quantized version using Tensorflow h( 2.7 MB )\n",
    "#     print(\"printing image\")\n",
    "#     print(image)\n",
    "    DNN = \"TF\"\n",
    "    if DNN == \"CAFFE\":\n",
    "        modelFile = \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "        configFile = \"models/deploy.prototxt\"\n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "    else:\n",
    "        modelFile = \"models/opencv_face_detector_uint8.pb\"\n",
    "        configFile = \"models/opencv_face_detector.pbtxt\"\n",
    "        net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "    conf_threshold = 0.7\n",
    "    outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,image)\n",
    "    return outOpencvDnn, bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:57.156939Z",
     "start_time": "2019-04-24T20:51:57.151446Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def train_model(self):\n",
    "        params_grid = [{\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': [1e-3, 1e-4],\n",
    "            'C': [1, 10, 100, 1000]\n",
    "            }, {\n",
    "            'kernel': ['linear'],\n",
    "            'C': [1, 10, 100, 1000]\n",
    "            }]\n",
    "        svm_model = GridSearchCV(SVC(), params_grid, cv=2)\n",
    "        svm_model.fit(self.X_train, self.y_train)\n",
    "        return svm_model.best_estimator_\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = load('svm_model.joblib')\n",
    "        return model\n",
    "    \n",
    "    def dump_model(self, model):\n",
    "        dump(model, 'svm_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:57.899406Z",
     "start_time": "2019-04-24T20:51:57.894035Z"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def train_model(self):\n",
    "        grid_values = {\n",
    "            'penalty': ['l1','l2'], \n",
    "            'C': [0.1,1,10,100,1000]\n",
    "        }\n",
    "        model = GridSearchCV(LogisticRegression(), grid_values,error_score='raise')\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return model.best_estimator_\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = load('lr_model.pkl')\n",
    "        return model\n",
    "    \n",
    "    def dump_model(self, model):\n",
    "        dump(model, 'lr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:51:59.042824Z",
     "start_time": "2019-04-24T20:51:59.037679Z"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def train_model(self):\n",
    "        model = BernoulliNB()\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return model\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = load('nb_model.pkl')\n",
    "        return model\n",
    "    \n",
    "    def dump_model(self, model):\n",
    "        dump(model, 'nb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:52:22.480716Z",
     "start_time": "2019-04-24T20:51:59.651627Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Usage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Usage'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d4127da4681a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For Keras NN model, we pass in model as 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfer_data_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-a6e28c080fa7>\u001b[0m in \u001b[0;36mfer_data_preprocessing\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m#Extracting and processing training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtraining_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Usage'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pixels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpixel_sequence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_pixels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Usage'"
     ]
    }
   ],
   "source": [
    "# For Keras NN model, we pass in model as 1\n",
    "X_train, y_train, X_test, y_test = fer_data_preprocessing(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:52:22.490005Z",
     "start_time": "2019-04-24T20:52:22.482283Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:52:22.699885Z",
     "start_time": "2019-04-24T20:52:22.493714Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "plt.imshow(X_train[i].reshape(X_train[i].shape[0],X_train[i].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:52:22.706277Z",
     "start_time": "2019-04-24T20:52:22.703333Z"
    }
   },
   "outputs": [],
   "source": [
    "training_errors = []\n",
    "testing_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:52:22.711172Z",
     "start_time": "2019-04-24T20:52:22.708199Z"
    }
   },
   "outputs": [],
   "source": [
    "model_NN = Keras_NN(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:52:22.715617Z",
     "start_time": "2019-04-24T20:52:22.713155Z"
    }
   },
   "outputs": [],
   "source": [
    "#uncomment the below code to train the model\n",
    "\n",
    "# trained_model = model_NN.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:52:24.387244Z",
     "start_time": "2019-04-24T20:52:22.718205Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model = model_NN.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:53:58.770102Z",
     "start_time": "2019-04-24T20:52:24.392104Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, acc = saved_model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Training loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "training_errors.append(acc)\n",
    "\n",
    "loss, acc = saved_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Testing loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "testing_errors.append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing data dimensions for SVM, PCA and NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:54:03.065849Z",
     "start_time": "2019-04-24T20:53:58.781927Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(100)\n",
    "X_train_reduced = pca.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_reduced = pca.transform(X_test.reshape(X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:54:03.077060Z",
     "start_time": "2019-04-24T20:54:03.069837Z"
    }
   },
   "outputs": [],
   "source": [
    "model_SVM = SVM(X_train_reduced, np.argmax(y_train, axis=1))\n",
    "# model_LR = LoisticRegression(X_train_reduced, np.argmax(y_train, axis=1))\n",
    "model_LR = LoisticRegression(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1))\n",
    "model_NB = NaiveBayes(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:54:03.115746Z",
     "start_time": "2019-04-24T20:54:03.079255Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model = model_LR.load_model()\n",
    "\n",
    "lr_acc = saved_model.score(X_train_reduced, np.argmax(y_train, axis=1))\n",
    "training_errors.append(lr_acc)\n",
    "\n",
    "lr_acc = saved_model.score(X_test_reduced, np.argmax(y_test, axis=1))\n",
    "testing_errors.append(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:54:03.122156Z",
     "start_time": "2019-04-24T20:54:03.118044Z"
    }
   },
   "outputs": [],
   "source": [
    "#uncomment the below code to train the model\n",
    "\n",
    "# model_LR.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:54:03.127200Z",
     "start_time": "2019-04-24T20:54:03.124601Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_NB.dump_model(model_NB.train_model()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:54:04.305055Z",
     "start_time": "2019-04-24T20:54:03.129264Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model = model_NB.load_model()\n",
    "\n",
    "lr_acc = saved_model.score(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1))\n",
    "training_errors.append(lr_acc)\n",
    "\n",
    "lr_acc = saved_model.score(X_test.reshape(X_test.shape[0], -1), np.argmax(y_test, axis=1))\n",
    "testing_errors.append(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T20:54:04.312988Z",
     "start_time": "2019-04-24T20:54:04.306988Z"
    }
   },
   "outputs": [],
   "source": [
    "training_errors\n",
    "testing_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T19:30:06.327241Z",
     "start_time": "2019-04-24T19:30:05.132497Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model = model_SVM.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-24T19:30:30.542Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model.predict(X_train.reshape(X_train.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-24T19:17:44.639Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model = model_SVM.load_model()\n",
    "\n",
    "lr_acc = saved_model.score(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1))\n",
    "training_errors.append(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T21:21:58.664680Z",
     "start_time": "2019-04-24T21:21:58.660948Z"
    }
   },
   "outputs": [],
   "source": [
    "#Adding the saved SVM model accuracies because calculating was taking too long\n",
    "\n",
    "training_errors.append(0.9984325472848236)\n",
    "testing_errors.append(0.31819448314293675)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T21:22:23.859783Z",
     "start_time": "2019-04-24T21:22:23.831998Z"
    }
   },
   "outputs": [],
   "source": [
    "model_names = [\"NeuralNet\",\"LogReg\",\"NaiveBayes\", \"SVM\"]\n",
    "training_acc_df = pd.DataFrame(training_errors ,columns=['accuracy'])\n",
    "training_acc_df['type'] = \"Training\"\n",
    "training_acc_df['model'] = model_names\n",
    "testing_acc_df = pd.DataFrame(testing_errors,columns=['accuracy'])\n",
    "testing_acc_df['type'] = \"Testing\"\n",
    "testing_acc_df['model'] = model_names\n",
    "acc_df = pd.concat([training_acc_df, testing_acc_df])\n",
    "acc_df['accuracy'] = acc_df['accuracy']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T21:22:30.520928Z",
     "start_time": "2019-04-24T21:22:30.321662Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = sns.barplot(x = 'model',y = \"accuracy\",hue=\"type\", data=acc_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
