{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(490, 640, 3)\n",
      "[[[  5   5   5]\n",
      "  [ 28  28  28]\n",
      "  [ 90  90  90]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [ 37  37  37]\n",
      "  [102 102 102]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  3   3   3]\n",
      "  [  1   1   1]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[175 175 175]\n",
      "  [177 177 177]\n",
      "  [180 180 180]\n",
      "  ...\n",
      "  [158 158 158]\n",
      "  [155 155 155]\n",
      "  [154 154 154]]\n",
      "\n",
      " [[171 171 171]\n",
      "  [174 174 174]\n",
      "  [178 178 178]\n",
      "  ...\n",
      "  [155 155 155]\n",
      "  [154 154 154]\n",
      "  [151 151 151]]\n",
      "\n",
      " [[218 218 218]\n",
      "  [220 220 220]\n",
      "  [222 222 222]\n",
      "  ...\n",
      "  [192 192 192]\n",
      "  [192 192 192]\n",
      "  [188 188 188]]]\n"
     ]
    }
   ],
   "source": [
    "# Face detection using opencv and neural nets\n",
    "# Works for webcam video\n",
    "# TODO : Configure this according to our input data\n",
    "\n",
    "from __future__ import division\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def detectFaceOpenCVDnn(net, frame):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "#     bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "#             bboxes.append([x1, y1, x2, y2])\n",
    "            if x1 > frameWidth or x1 < 0 or x2 > frameWidth or x2 < 0:\n",
    "                continue\n",
    "            else:\n",
    "                print(frameOpencvDnn.shape)\n",
    "                print(frameOpencvDnn)\n",
    "                grayOpenDnn = gray = cv2.cvtColor(frameOpencvDnn, cv2.COLOR_BGR2GRAY)\n",
    "                croppedOpenDnn = gray[y1:y2,x1:x2]\n",
    "#                 cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return croppedOpenDnn\n",
    "\n",
    "def face_reduction(image):\n",
    "    # OpenCV DNN supports 2 networks.\n",
    "    # 1. FP16 version of the original caffe implementation ( 5.4 MB )\n",
    "    # 2. 8 bit Quantized version using Tensorflow h( 2.7 MB )\n",
    "    DNN = \"TF\"\n",
    "    if DNN == \"CAFFE\":\n",
    "        modelFile = \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "        configFile = \"models/deploy.prototxt\"\n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "    else:\n",
    "        modelFile = \"models/opencv_face_detector_uint8.pb\"\n",
    "        configFile = \"models/opencv_face_detector.pbtxt\"\n",
    "        net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "    conf_threshold = 0.9\n",
    "    tt_opencvDnn = 0\n",
    "    t = time.time()\n",
    "    outOpencvDnn = detectFaceOpenCVDnn(net,image)\n",
    "    return outOpencvDnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
