{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:16.801721Z",
     "start_time": "2019-04-24T18:00:13.589833Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump, load\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
    "%matplotlib inline\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:16.820415Z",
     "start_time": "2019-04-24T18:00:16.803666Z"
    }
   },
   "outputs": [],
   "source": [
    "def fer_data_preprocessing(model):\n",
    "    fer_path = '../Data/challenges-in-representation-learning-facial-expression-recognition-challenge/fer2013/fer2013.csv'\n",
    "    \n",
    "    #Loading the data from file system\n",
    "    data = pd.read_csv(fer_path)\n",
    "    \n",
    "    width, height = 48, 48\n",
    "    image_size = (width, height)\n",
    "    \n",
    "    #Extracting and processing training data\n",
    "    training_pixels = data[data['Usage'] == 'Training']['pixels'].tolist()\n",
    "    X_train = []\n",
    "    for pixel_sequence in training_pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        X_train.append(face.astype('float32'))\n",
    "    X_train = np.asarray(X_train)\n",
    "    if model == 1:\n",
    "        X_train = np.expand_dims(X_train, -1)\n",
    "    elif model == 2:\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        \n",
    "    y_train = pd.get_dummies(data[data['Usage'] == 'Training']['emotion']).values\n",
    "    \n",
    "    \n",
    "    #Loading and processing Test data\n",
    "    test_pixels = data[data['Usage'] == 'PublicTest']['pixels'].tolist()\n",
    "    X_test = []\n",
    "    for pixel_sequence in test_pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        X_test.append(face.astype('float32'))\n",
    "    X_test = np.asarray(X_test)\n",
    "    if model == 1:\n",
    "        X_test = np.expand_dims(X_test, -1)\n",
    "    elif model == 2:\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    y_test = pd.get_dummies(data[data['Usage'] == 'PublicTest']['emotion']).values\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Neural Network Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:16.850420Z",
     "start_time": "2019-04-24T18:00:16.828521Z"
    }
   },
   "outputs": [],
   "source": [
    "class Keras_NN:\n",
    "    def __init__(self,X_train, Y_train):\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        \n",
    "    def train_model(self):\n",
    "        IMG_SIZE = 48\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "        model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(7, activation = 'softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model.fit(self.X_train, self.Y_train, batch_size=len(self.X_train)//20, epochs=20, verbose=1)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = load_model('keras_on_fer')\n",
    "        return model\n",
    "    \n",
    "    def save_model(self, model, name):\n",
    "        model.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebCam Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:16.871175Z",
     "start_time": "2019-04-24T18:00:16.852945Z"
    }
   },
   "outputs": [],
   "source": [
    "def display_emotions(model, videoFaces, frame, bboxes):\n",
    "    '''\n",
    "    Fetches the emotions by using model prediction and adds \n",
    "    them to the output frame\n",
    "    '''\n",
    "    y_translation = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "    outputFrame = frame.copy()\n",
    "    predictions = model.predict(videoFaces)\n",
    "    for i in range(len(bboxes)):\n",
    "        emotion = y_translation[np.argmax(predictions[i])]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(outputFrame, emotion, (bboxes[i][0] -1 ,bboxes[i][1] - 1), font, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "        cv2.rectangle(outputFrame, (bboxes[i][0], bboxes[i][1]), (bboxes[i][2], bboxes[i][3]), (0, 255, 0), int(round(outputFrame.shape[0]/150)), 8)\n",
    "    return outputFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:17.271063Z",
     "start_time": "2019-04-24T18:00:17.261957Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_webcam_feed(model):\n",
    "    '''\n",
    "    Initializes webcam video for live classification\n",
    "    Extracts faces from the frame\n",
    "    Outputs the frame with predicted emotions to a window \n",
    "    '''\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    hasFrame, frame = cap.read()\n",
    "    #TODO : Handle cases for face going outside the frame\n",
    "    frame_count = 0\n",
    "    tt_opencvDnn = 0\n",
    "    while(1):\n",
    "        try:\n",
    "            hasFrame, frame = cap.read()\n",
    "            if not hasFrame:\n",
    "                break\n",
    "            frame_count += 1\n",
    "            outputFrame = frame\n",
    "            \n",
    "            #Gives a list of gray-scale images in webcam feed\n",
    "            videoFaces, bboxes = face_reduction(frame)\n",
    "            videoFaces = np.array(videoFaces)\n",
    "            if videoFaces.shape[0] != 0:\n",
    "                print(videoFaces.shape)\n",
    "                videoFaces = videoFaces.reshape((videoFaces.shape[0],videoFaces.shape[1],videoFaces.shape[2],1))\n",
    "                outputFrame = display_emotions(model, videoFaces, frame, bboxes)\n",
    "            cv2.imshow(\"frame\", outputFrame)\n",
    "            k = cv2.waitKey(10)\n",
    "            \n",
    "            # quits window when escape key is pressed\n",
    "            if k == 27:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(\"Exception is \")\n",
    "            print(e)\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:19.098080Z",
     "start_time": "2019-04-24T18:00:19.088158Z"
    }
   },
   "outputs": [],
   "source": [
    "def detectFaceOpenCVDnn(net, frame):\n",
    "    result = []\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    conf_threshold = 0.7\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            if x1 > frameWidth or x1 < 0 or x2 > frameWidth or x2 < 0 or y1 < 0 or y1 > frameHeight or y2 < 0 or y2 > frameHeight:\n",
    "                continue\n",
    "            else:\n",
    "                grayOpenDnn = gray = cv2.cvtColor(frameOpencvDnn, cv2.COLOR_BGR2GRAY)\n",
    "                croppedOpenDnn = cv2.resize(gray[y1:y2,x1:x2], (48,48)) \n",
    "                result.append(croppedOpenDnn)\n",
    "    return result, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:20.324944Z",
     "start_time": "2019-04-24T18:00:20.318866Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_reduction(image):\n",
    "    # OpenCV DNN supports 2 networks.\n",
    "    # 1. FP16 version of the original caffe implementation ( 5.4 MB )\n",
    "    # 2. 8 bit Quantized version using Tensorflow h( 2.7 MB )\n",
    "#     print(\"printing image\")\n",
    "#     print(image)\n",
    "    DNN = \"TF\"\n",
    "    if DNN == \"CAFFE\":\n",
    "        modelFile = \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "        configFile = \"models/deploy.prototxt\"\n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "    else:\n",
    "        modelFile = \"models/opencv_face_detector_uint8.pb\"\n",
    "        configFile = \"models/opencv_face_detector.pbtxt\"\n",
    "        net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "    conf_threshold = 0.7\n",
    "    outOpencvDnn, bboxes = detectFaceOpenCVDnn(net,image)\n",
    "    return outOpencvDnn, bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:21.633855Z",
     "start_time": "2019-04-24T18:00:21.625439Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def train_model(self):\n",
    "        params_grid = [{\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': [1e-3, 1e-4],\n",
    "            'C': [1, 10, 100, 1000]\n",
    "            }, {\n",
    "            'kernel': ['linear'],\n",
    "            'C': [1, 10, 100, 1000]\n",
    "            }]\n",
    "        svm_model = GridSearchCV(SVC(), params_grid, cv=2)\n",
    "        svm_model.fit(self.X_train, self.y_train)\n",
    "        return svm_model.best_estimator_\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = load('svm_model.joblib')\n",
    "        return model\n",
    "    \n",
    "    def dump_model(self, model):\n",
    "        dump(model, 'svm_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:22.617892Z",
     "start_time": "2019-04-24T18:00:22.608103Z"
    }
   },
   "outputs": [],
   "source": [
    "class LoisticRegression:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def train_model(self):\n",
    "        grid_values = {\n",
    "            'penalty': ['l1','l2'], \n",
    "            'C': [0.1,1,10,100,1000]\n",
    "        }\n",
    "        model = GridSearchCV(LogisticRegression(), grid_values,error_score='raise')\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return model.best_estimator_\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = load('lr_model.pkl')\n",
    "        return model\n",
    "    \n",
    "    def dump_model(self, model):\n",
    "        dump(model, 'lr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:24.071889Z",
     "start_time": "2019-04-24T18:00:24.067759Z"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def train_model(self):\n",
    "        model = BernoulliNB()\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        return model\n",
    "    \n",
    "    def load_model(self):\n",
    "        model = load('nb_model.pkl')\n",
    "        return model\n",
    "    \n",
    "    def dump_model(self, model):\n",
    "        dump(model, 'nb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:51.362426Z",
     "start_time": "2019-04-24T18:00:28.461976Z"
    }
   },
   "outputs": [],
   "source": [
    "# For Keras NN model, we pass in model as 1\n",
    "X_train, y_train, X_test, y_test = fer_data_preprocessing(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:00:51.373700Z",
     "start_time": "2019-04-24T18:00:51.364037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n",
      "(3589, 48, 48, 1)\n",
      "(28709, 7)\n",
      "(3589, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:14:46.252526Z",
     "start_time": "2019-04-24T18:14:46.245662Z"
    }
   },
   "outputs": [],
   "source": [
    "training_errors = []\n",
    "testing_errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:01:09.707162Z",
     "start_time": "2019-04-24T18:01:09.702023Z"
    }
   },
   "outputs": [],
   "source": [
    "model_NN = Keras_NN(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T16:08:40.419358Z",
     "start_time": "2019-04-24T16:08:16.840901Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-91e4082e9054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_NN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-662191bcfbfe>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_proj/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/ml_proj/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_proj/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_proj/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml_proj/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# trained_model = model_NN.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:14:54.552521Z",
     "start_time": "2019-04-24T18:14:52.562092Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "saved_model = model_NN.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:16:46.647804Z",
     "start_time": "2019-04-24T18:14:54.554810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7082138153103112, acc: 0.7369117698324292\n",
      "\n",
      "Testing loss: 1.480964902201945, acc: 0.5293953747894147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss, acc = saved_model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Training loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "training_errors.append(acc)\n",
    "\n",
    "loss, acc = saved_model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Testing loss: {}, acc: {}\\n'.format(loss, acc))\n",
    "testing_errors.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T16:08:40.432428Z",
     "start_time": "2019-04-24T16:07:45.123Z"
    }
   },
   "outputs": [],
   "source": [
    "get_webcam_feed(saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing data dimensions for SVM, PCA and NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:05:39.796676Z",
     "start_time": "2019-04-24T18:05:34.065248Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(100)\n",
    "X_train_reduced = pca.fit_transform(X_train.reshape(X_train.shape[0], -1))\n",
    "X_test_reduced = pca.transform(X_test.reshape(X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:16:46.658751Z",
     "start_time": "2019-04-24T18:16:46.650416Z"
    }
   },
   "outputs": [],
   "source": [
    "model_SVM = SVM(X_train_reduced, np.argmax(y_train, axis=1))\n",
    "# model_LR = LoisticRegression(X_train_reduced, np.argmax(y_train, axis=1))\n",
    "model_LR = LoisticRegression(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1))\n",
    "model_NB = NaiveBayes(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:16:46.736726Z",
     "start_time": "2019-04-24T18:16:46.661055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.3 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.20.3 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.20.3 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "saved_model = model_LR.load_model()\n",
    "\n",
    "lr_acc = saved_model.score(X_train_reduced, np.argmax(y_train, axis=1))\n",
    "training_errors.append(lr_acc)\n",
    "\n",
    "lr_acc = saved_model.score(X_test_reduced, np.argmax(y_test, axis=1))\n",
    "testing_errors.append(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-24T16:49:42.373Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_LR.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:11:29.468776Z",
     "start_time": "2019-04-24T18:11:27.786913Z"
    }
   },
   "outputs": [],
   "source": [
    "model_NB.dump_model(model_NB.train_model()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:16:48.516666Z",
     "start_time": "2019-04-24T18:16:46.739148Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model = model_NB.load_model()\n",
    "\n",
    "lr_acc = saved_model.score(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1))\n",
    "training_errors.append(lr_acc)\n",
    "\n",
    "lr_acc = saved_model.score(X_test.reshape(X_test.shape[0], -1), np.argmax(y_test, axis=1))\n",
    "testing_errors.append(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:16:48.552069Z",
     "start_time": "2019-04-24T18:16:48.525485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7369117698324292, 0.37354139816782195, 0.26395903723571007]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-24T18:16:30.740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visheshhemnani/anaconda3/envs/ml_proj/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator SVC from version 0.20.3 when using version 0.20.0. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "saved_model = model_SVM.load_model()\n",
    "\n",
    "lr_acc = saved_model.score(X_train.reshape(X_train.shape[0], -1), np.argmax(y_train, axis=1))\n",
    "training_errors.append(lr_acc)\n",
    "\n",
    "lr_acc = saved_model.score(X_test.reshape(X_test.shape[0], -1), np.argmax(y_test, axis=1))\n",
    "testing_errors.append(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-04-24T18:17:04.714Z"
    }
   },
   "outputs": [],
   "source": [
    "training_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
