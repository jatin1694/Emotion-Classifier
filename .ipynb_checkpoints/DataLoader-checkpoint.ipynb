{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:50:38.963033Z",
     "start_time": "2019-04-05T18:50:34.443056Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:50:38.973987Z",
     "start_time": "2019-04-05T18:50:38.965722Z"
    }
   },
   "outputs": [],
   "source": [
    "def list_files(startpath, return_neutral = False):\n",
    "\n",
    "    all_files = []\n",
    "    neutral_files = []\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        files = sorted(files)\n",
    "        if files and files[-1][-4] == '.' and files[0][-4] == '.':\n",
    "            all_files.append(root + '/' + files[-1])\n",
    "            neutral_files.append(root + '/' + files[0])\n",
    "\n",
    "    if return_neutral:\n",
    "        return sorted(all_files), sorted(neutral_files)\n",
    "    else:\n",
    "        return sorted(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:50:38.986709Z",
     "start_time": "2019-04-05T18:50:38.978475Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_matching(X, y):\n",
    "    final_X = []\n",
    "    final_y = []\n",
    "    i, j = 0, 0\n",
    "    while i < len(X):\n",
    "        X_split = X[i].split('/')\n",
    "        y_split = y[j].split('/')\n",
    "        if X_split[3] == y_split[3] and X_split[4] == y_split[4]:\n",
    "            final_X.append(X[i])\n",
    "            final_y.append(y[j])\n",
    "            j+=1\n",
    "        i+=1\n",
    "    return final_X, final_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:50:39.002635Z",
     "start_time": "2019-04-05T18:50:38.989134Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_Y(y):\n",
    "    res_y = []\n",
    "    for file in y:\n",
    "        with open(file) as f:\n",
    "            for line in f.readlines():\n",
    "                res_y.append(float(line))\n",
    "    return np.array(res_y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:50:39.012735Z",
     "start_time": "2019-04-05T18:50:39.005879Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_X(X):\n",
    "    res_X = []\n",
    "    try:\n",
    "        for file in X:\n",
    "            img = cv2.imread(file,1) # reads image as color\n",
    "            img = face_reduction(img)\n",
    "            res_X.append(img)\n",
    "    except Exception as e:\n",
    "        print(\"Exception in X\")\n",
    "        print(X)\n",
    "    return np.array(res_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:50:39.026824Z",
     "start_time": "2019-04-05T18:50:39.015956Z"
    }
   },
   "outputs": [],
   "source": [
    "def detectFaceOpenCVDnn(net, frame):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "#     bboxes = []\n",
    "    conf_threshold = 0.7\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "#             bboxes.append([x1, y1, x2, y2])\n",
    "            if x1 > frameWidth or x1 < 0 or x2 > frameWidth or x2 < 0:\n",
    "                continue\n",
    "            else:\n",
    "#                 print(frameOpencvDnn.shape)\n",
    "#                 print(frameOpencvDnn)\n",
    "                grayOpenDnn = gray = cv2.cvtColor(frameOpencvDnn, cv2.COLOR_BGR2GRAY)\n",
    "                croppedOpenDnn = cv2.resize(gray[y1:y2,x1:x2], (200,200)) \n",
    "#                 cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return croppedOpenDnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:50:39.036811Z",
     "start_time": "2019-04-05T18:50:39.029893Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_reduction(image):\n",
    "    # OpenCV DNN supports 2 networks.\n",
    "    # 1. FP16 version of the original caffe implementation ( 5.4 MB )\n",
    "    # 2. 8 bit Quantized version using Tensorflow h( 2.7 MB )\n",
    "#     print(\"printing image\")\n",
    "#     print(image)\n",
    "    DNN = \"TF\"\n",
    "    if DNN == \"CAFFE\":\n",
    "        modelFile = \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "        configFile = \"models/deploy.prototxt\"\n",
    "        net = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "    else:\n",
    "        modelFile = \"models/opencv_face_detector_uint8.pb\"\n",
    "        configFile = \"models/opencv_face_detector.pbtxt\"\n",
    "        net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "\n",
    "    conf_threshold = 0.7\n",
    "    outOpencvDnn = detectFaceOpenCVDnn(net,image)\n",
    "    return outOpencvDnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:52:16.148803Z",
     "start_time": "2019-04-05T18:50:39.039387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of unique training points are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7.]),\n",
       " array([583,  44,  17,  59,  24,  69,  27,  83]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'neutral', 1: 'anger', 2: 'contempt', 3: 'disgust', 4: 'fear', 5: 'happy', 6: 'sadness', 7: 'surprise'}\n"
     ]
    }
   ],
   "source": [
    "y_translation = {0:\"neutral\", 1:\"anger\", 2:\"contempt\", 3:\"disgust\", 4:\"fear\", 5:\"happy\", 6:\"sadness\", 7:\"surprise\"}\n",
    "X, X_neutral = list_files('../Data/cohn-kanade-images/', return_neutral= True)\n",
    "y = list_files('../Data/Emotion/')\n",
    "X, y = find_matching(X, y)\n",
    "y = read_Y(y)\n",
    "X = read_X(X)\n",
    "X_neutral = read_X(X_neutral)\n",
    "\n",
    "X_train= np.vstack((X, X_neutral))\n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2],1))\n",
    "total_y = np.hstack((y, np.zeros(X_neutral.shape[0]))).reshape(-1,1)\n",
    "\n",
    "oht = OneHotEncoder(categories='auto', sparse=False)\n",
    "y_train = oht.fit_transform(total_y)\n",
    "print(\"the total number of unique training points are: \")\n",
    "np.unique(total_y, return_counts=True)\n",
    "print(y_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KERAS NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:52:16.724969Z",
     "start_time": "2019-04-05T18:52:16.151311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/visheshhemnani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/visheshhemnani/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 200\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(96, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(8, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T18:52:16.763603Z",
     "start_time": "2019-04-05T18:52:16.727084Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-05T19:00:59.792525Z",
     "start_time": "2019-04-05T18:52:16.766050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/visheshhemnani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "906/906 [==============================] - 31s 34ms/step - loss: 1.2648 - acc: 0.6556\n",
      "Epoch 2/20\n",
      "906/906 [==============================] - 29s 32ms/step - loss: 0.7353 - acc: 0.7903\n",
      "Epoch 3/20\n",
      "906/906 [==============================] - 30s 33ms/step - loss: 0.5499 - acc: 0.8444\n",
      "Epoch 4/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.4255 - acc: 0.8642\n",
      "Epoch 5/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.3435 - acc: 0.8841\n",
      "Epoch 6/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.2541 - acc: 0.9283\n",
      "Epoch 7/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.1809 - acc: 0.9437\n",
      "Epoch 8/20\n",
      "906/906 [==============================] - 26s 28ms/step - loss: 0.2320 - acc: 0.9393\n",
      "Epoch 9/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.1804 - acc: 0.9470\n",
      "Epoch 10/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.2356 - acc: 0.9172\n",
      "Epoch 11/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.3158 - acc: 0.8974\n",
      "Epoch 12/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.1940 - acc: 0.9382\n",
      "Epoch 13/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.1325 - acc: 0.9625\n",
      "Epoch 14/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.1008 - acc: 0.9669\n",
      "Epoch 15/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.0790 - acc: 0.9757\n",
      "Epoch 16/20\n",
      "906/906 [==============================] - 26s 29ms/step - loss: 0.0617 - acc: 0.9823\n",
      "Epoch 17/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.0505 - acc: 0.9845\n",
      "Epoch 18/20\n",
      "906/906 [==============================] - 25s 28ms/step - loss: 0.0666 - acc: 0.9779\n",
      "Epoch 19/20\n",
      "906/906 [==============================] - 26s 29ms/step - loss: 0.0561 - acc: 0.9823\n",
      "Epoch 20/20\n",
      "906/906 [==============================] - 26s 28ms/step - loss: 0.0543 - acc: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a49d30c88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=50, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
