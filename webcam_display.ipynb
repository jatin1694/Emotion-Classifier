{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WebCam Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "%run face_detection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_emotions(model, videoFaces, frame, bboxes):\n",
    "    '''\n",
    "    Fetches the emotions by using model prediction and adds \n",
    "    them to the output frame\n",
    "    '''\n",
    "    y_translation = {\n",
    "    0: 'Angry',\n",
    "    1: 'Disgust',\n",
    "    2: 'Fear',\n",
    "    3: 'Happy',\n",
    "    4: 'Sad',\n",
    "    5: 'Surprise',\n",
    "    6: 'Neutral'\n",
    "}\n",
    "    outputFrame = frame.copy()\n",
    "    predictions = model.predict(videoFaces)\n",
    "    for i in range(len(bboxes)):\n",
    "        emotion = y_translation[np.argmax(predictions[i])]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(outputFrame, emotion, (bboxes[i][0] -1 ,bboxes[i][1] - 1), font, 1, (0,255,0), 2, cv2.LINE_AA)\n",
    "        cv2.rectangle(outputFrame, (bboxes[i][0], bboxes[i][1]), (bboxes[i][2], bboxes[i][3]), (0, 255, 0), int(round(outputFrame.shape[0]/150)), 8)\n",
    "    return outputFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webcam_feed(model):\n",
    "    '''\n",
    "    Initializes webcam video for live classification\n",
    "    Extracts faces from the frame\n",
    "    Outputs the frame with predicted emotions to a window \n",
    "    '''\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    hasFrame, frame = cap.read()\n",
    "    #TODO : Handle cases for face going outside the frame\n",
    "    frame_count = 0\n",
    "    tt_opencvDnn = 0\n",
    "    while(1):\n",
    "        try:\n",
    "            hasFrame, frame = cap.read()\n",
    "            if not hasFrame:\n",
    "                break\n",
    "            frame_count += 1\n",
    "            outputFrame = frame\n",
    "            \n",
    "            #Gives a list of gray-scale images in webcam feed\n",
    "            videoFaces, bboxes = face_reduction(frame)\n",
    "            videoFaces = np.array(videoFaces)\n",
    "            if videoFaces.shape[0] != 0:\n",
    "                print(videoFaces.shape)\n",
    "                videoFaces = videoFaces.reshape((videoFaces.shape[0],videoFaces.shape[1],videoFaces.shape[2],1))\n",
    "                outputFrame = display_emotions(model, videoFaces, frame, bboxes)\n",
    "            cv2.imshow(\"frame\", outputFrame)\n",
    "            k = cv2.waitKey(10)\n",
    "            \n",
    "            # quits window when escape key is pressed\n",
    "            if k == 27:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(\"Exception is \")\n",
    "            print(e)\n",
    "            break\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
